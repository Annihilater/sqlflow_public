The source of metadata comes from 2 sources, one is extracted from the database, the other is collect from the SQL scripts.

In order to export the metadata collected by the SQLFlow, we need to know the structure that how SQLFlow save the

metadata in the data lineage model.

### 1. The database objects that need to be exported

1. cluster
2. db
3. table/view
4. column
5. process, this is usually the query that transform the data, such as a stored proceudure, an insert statement and etc.

#### defualt value for db and schema name

If a db or schema is not mentioned in a SQL query, we use `default` as the name of the missing db or schema.

The default schema for SQL Server database is `dbo`.

### metadata from the database

SQLFlow use the grabit tool to extract metadata from a database instance and save it in the format defined in this document.

https://e.gitee.com/gudusoft/docs/591884/file/1434789?sub_id=4091727

#### cluster

The related element in the exported json file is:  `physicalInstance`

#### db

The related element in the exported json file is: `databases`

#### table/view

The related element in the exported json file is: `databases->tables`

#### column

The related element in the exported json file is: `databases->tables->column`

### 2. metadata from the SQL script

There is no `cluster` and `db` information in the json file generated by the SQLFlow after analyzing the SQL script and stored procedure.

The database objects is saved in a json array `dbobjs` with the `name` and `type` property.

```json
{
  "dbvendor": "dbvoracle",
  "dbobjs": [
    {
      "id": "37",
      "name": "Query Create View",
      "type": "process"
    },
    {
      "id": "4",
      "schema": "scott",
      "name": "scott.emp",
      "type": "table",
      "columns": [
        {
          "id": "41",
          "name": "deptno"
        },
        {
          "id": "42",
          "name": "sal"
        },
        {
          "id": "43",
          "name": "city"
        }
      ]
    }
  ]
}

```

#### table/view

table/view can be located via `dbobjs[index]` with the `type` set to `table`.

#### column

column can be located via `dbobjs[index]->columns[index]`

### 3. uniquely identify a database object

#### cluster

1. Hive, the default cluster name is`primary`
2. Oracle, the cluster name is`physicalInstance`
3. SQL Server, the cluster name is the`servername`

#### db

The unique name of a database is in syntax like: `dbname@cluster`.  Such as `ABCDPROD@xzy001db03.ddc.nba.com`

#### table/view

The unique name of a table is `dbname.tablename@cluster`, or `dbname.schemaname.tablename@cluster` .

Such as `ABCDPROD.HARDWARE.SUBRACK_I_TRG@xzy001db03.ddc.nba.com`

#### column

The unique name of a column is `dbname.tablename.columnname@cluster`, or `dbname.schemaname.tablename.columnname@cluster` .

#### process

The unique name of a process is `dbname.procedureName.queryHashId@cluster`.

The `proedureName` should be fully qualified.  If the SQL query is not inside a stored proceure, then `procedureName` will use `batchQueries` as it name. `queryHashId` is the hash code of the SQL query that do the transformation, The `queryHashId` can be generated by calling the GSP library via `TParseTreeNode.getMd5()` method.
